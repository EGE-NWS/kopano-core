Opportunistic deduplication strategy


== Overview ==

Deduplication happens by linking to an existing attachment, i.e. making a
reference to a shared block of data and track the in-use state.

Design requirement: Must work with filesystems like VFAT, smbfs/CIFS.
POSIX-style hardlinks, symbolic links, or file locks may not exist and their
presence cannot be relied upon.

Design wishlist item: The filesystem itself should encode all the linkage
metadata without needing an extra database component of any sort. (Such would
add latency, and file-based databases like sqlite even have a hard time due to
the absence of locking and protection from concurrent writers.)

Design wishlist item: Avoid in-place file writes. This way,
locks can be dispensed with, and atomics can suffice.

Design note: In practice, reference decrements are rarer than reference
increments. If there is a trade-off to be made, decrements should preferably
take the hit.


== States of an attachment ==

digraph {
	non-existent -> complete -> no-holders ->
	no-intents -> non-existent;
};

The state change from "non-existent" to "complete" ought to be atomic (no
intermediate states), lest it could block another writer or disable
deduplication by staying in some intermediate state indefinitely.

Because there are no intermediate states between "non-existent" and "complete",
the cases "no-holders" and "no-intents" unambiguously mean that the attachment
is in the process of deletion.

UAS expects the underlying storage mechanism to exhibit the atomicity and
consistency requirements laid out in [1].

	* Test-and-create (open(2) with O_EXCL) for a file must be atomic
	* Renaming of a file must be atomic
	* Deletion of a file must be atomic
	* Creation of a directory must be atomic
	* Renaming of a directory must be atomic
	  (in particular when that directory already has contents)
	* Deletion of an empty directory must be atomic

[1] https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/filesystem/introduction.html#Core_Expectations_of_a_Hadoop_Compatible_FileSystem

S3 does not offer an atomic rename operation and therefore cannot support UAS.
(In S3, rename is copy+delete, which means that another kopano-server instance
accessing the same S3 bucket could observe a state inbetween "non-existent" and
"complete".)


== Names for directories/files ==

Because uploading an attachment is not an atomic operation, attachments will
carry a temporary name while in that state. This name needs to be chosen such
that there is no collision with any other kopano-server instance also uploading
something (possibly the same content). This is referred to as the S-type
(server-sepcific) name.

When the upload is complete, the attachment will be renamed to the so-called
H-type (hash-based) name which depends solely on the content and no
server-specific characteristics. This name must not collide with any S-type
names.

=== files_v2 ===

In the files_v2 implementation of UAS, the H-type name in files_v2 is the
base-16 representation of the SHA-256 content hash, which consists solely of
[0-9a-f] characters. The S-type name is constructed from 's', the server GUID,
'i', and a per-server monotonically increasing counter. The presence of 's'
(which is outside the [0-9a-f] alphabet) means it will never collide with any
H-type name.

	H: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
	   (<hash>)
	S: scf1e8c14e54505f60aa10ceb8d5d8ab3i43981
	   (s<server_guid>i<instance_id>)

To facilitate directory fanout, the actual S/H names used in files_v2 actually
differ a little, but without changing the aforementioned anti-collision
properties.

	H: e3/b0/c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
	S: cd/ab/scf1e8c14e54505f60aa10ceb8d5d8ab3i43981

The naming scheme in files_v2 also allows switching the hash algorithm, so long
as the new names are collision-free, which is possible by using more of the
remaining characters from [^0-9a-fsi]. A move to SHA-512 could look like

	H: xcf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e
	H: cf/83/xe1357eefb8bdf154... (fanout variant)


== Algorithm ==

1. Creation of a reference to an existing attachment.

1a. Create an “intent to link” file <hash>/intent/s<server_guid>i<instance_id>.
    If the "<hash>/intent" directory does not exist, there is no attachment yet
    as far as this uploader is concerned; goto #2.

1b. Successful intent creation indicates the attachment is already present
    (upload was completed in the past) and that, from now on, the content file
    will not go away (cf. #3c).

1c. Rename <hash>/intent/s<server_guid>i<instance_id> to
    <hash>/holder/s<server_guid>i<instance_id>. If "holder" did not exist, we
    know that the attachment was undergoing deletion by another party due to
    reaching 0 holders (#3b). That deletion will be canceled by that party due
    to the presence of our intent-to-link file (#3c).

    The "holder" directory is recreated by us and the rename is attempted
    again. On success, we are now a co-owner of the attachment. Else, proceed
    to #2.

2. Creation of attachment

2a. Upload the attachment structure into a temporary directory (S-type name).
    This always succeeds in the context of this UAS algorithm.
    s<server_guid>i<instance_id>/intent/ (directory of future holders)
    s<server_guid>i<instance_id>/holders/ (directory of present holders)
    s<server_guid>i<instance_id>/content (content file)
    s<server_guid>i<instance_id>/holders/s<server_guid>i<instance_id>

2b. Atomically rename s<server_guid>i<instance_id> to <hash>.

    If successful, we were the first uploader. Record <instance_id> => <hash>
    in the local database. Done.

2c. If unsuccessful, some other party must have uploaded the attachment at the
    same time and managed to finish first (#2b), or, the directory is
    undergoing final deletion (#3d).

    Retry from #1 for a limited number of tries. (If linking subsequently
    succeeds, the uploaded directory from #2a is removed. Else, if linking in
    #1a fails due to #3c, the algorithm goes to #2b again.) If retries are
    exhausted however, record <instance_id> => s<server_guid>i<instance_id> in
    the local database. Done.

3. Deletion of attachment

3a. Remove <d>/holder/s<server_guid>i<instance_id>, where <d> is whatever was
    recorded in the local database (<hash> or
    s<server_guid>i<instance_id>).

3b. Attempt to remove <d>/holder.
    If this fails, there are other holders; stop and done.

3c. Attempt to remove <d>/intent.
    If this fails, there are aspiring new holders; stop and done.

3d. Recursively remove <d>. Done.
